{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63ad9b57-5fbd-4a2f-a444-0af394c29808",
   "metadata": {},
   "source": [
    "Stratified k-fold Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b99afcd-2447-4ed3-80ae-ead5d723fa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Dataset details\n",
    "base_dir = r\"D:\\3rd sem Project\\Secondary dataset\\CXR collection\\17000 Dataset\\Dataset\"\n",
    "output_dir = r\"E:\\Modified Dataset\"\n",
    "train_dir = os.path.join(base_dir, \"train\")\n",
    "test_dir = os.path.join(base_dir, \"test\")  # Fixed test dataset directory\n",
    "classes = [\"NORMAL\", \"PNEUMONIA\", \"ABNORMAL\"]\n",
    "\n",
    "# Create a list of all images and their labels (from the training directory)\n",
    "image_paths = []\n",
    "labels = []\n",
    "\n",
    "for cls in classes:\n",
    "    cls_dir = os.path.join(train_dir, cls)\n",
    "    for img in os.listdir(cls_dir):\n",
    "        image_paths.append(os.path.join(cls_dir, img))\n",
    "        labels.append(cls)\n",
    "\n",
    "# Convert to a DataFrame\n",
    "data = pd.DataFrame({\"image_path\": image_paths, \"label\": labels})\n",
    "\n",
    "# Stratified K-Fold Cross-Validation configuration\n",
    "n_splits = 5  # Number of folds\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Loop through each fold\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(data, data[\"label\"])):\n",
    "    print(f\"Processing Fold {fold + 1}...\")\n",
    "    fold_dir = os.path.join(output_dir, f\"Fold_{fold + 1}\")\n",
    "    fold_train_dir = os.path.join(fold_dir, \"Train\")\n",
    "    fold_val_dir = os.path.join(fold_dir, \"Validation\")\n",
    "    fold_test_dir = os.path.join(fold_dir, \"Test\")\n",
    "\n",
    "    # Create directories for Train, Validation, and Test\n",
    "    for folder in [fold_train_dir, fold_val_dir, fold_test_dir]:\n",
    "        for cls in classes:\n",
    "            os.makedirs(os.path.join(folder, cls), exist_ok=True)\n",
    "\n",
    "    # Split data into training and validation sets for the current fold\n",
    "    train_data = data.iloc[train_idx]\n",
    "    val_data = data.iloc[val_idx]\n",
    "\n",
    "    # Copy training images\n",
    "    for _, row in train_data.iterrows():\n",
    "        src = row[\"image_path\"]\n",
    "        label = row[\"label\"]\n",
    "        dst = os.path.join(fold_train_dir, label, os.path.basename(src))\n",
    "        shutil.copy(src, dst)\n",
    "\n",
    "    # Copy validation images\n",
    "    for _, row in val_data.iterrows():\n",
    "        src = row[\"image_path\"]\n",
    "        label = row[\"label\"]\n",
    "        dst = os.path.join(fold_val_dir, label, os.path.basename(src))\n",
    "        shutil.copy(src, dst)\n",
    "\n",
    "    # Copy fixed testing dataset\n",
    "    for cls in classes:\n",
    "        cls_test_dir = os.path.join(test_dir, cls)\n",
    "        for img in os.listdir(cls_test_dir):\n",
    "            src = os.path.join(cls_test_dir, img)\n",
    "            dst = os.path.join(fold_test_dir, cls, os.path.basename(img))\n",
    "            shutil.copy(src, dst)\n",
    "\n",
    "print(\"Stratified K-Fold Cross-Validation dataset splits created in E:\\\\Modified Dataset.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8782a5c2-e960-47c5-882c-7e575434d5d4",
   "metadata": {},
   "source": [
    "#Monte Carlo Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d0f2d7-d1d8-4c49-bea4-2ea90cccf16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Dataset details\n",
    "base_dir = r\"D:\\3rd sem Project\\Secondary dataset\\CXR collection\\17000 Dataset\\Dataset\"\n",
    "output_dir = r\"E:\\Modified Dataset\"\n",
    "train_dir = os.path.join(base_dir, \"train\")\n",
    "test_dir = os.path.join(base_dir, \"test\")  # Fixed test dataset directory\n",
    "classes = [\"NORMAL\", \"PNEUMONIA\", \"ABNORMAL\"]\n",
    "\n",
    "# Create a list of all images and their labels (from the training directory)\n",
    "image_paths = []\n",
    "labels = []\n",
    "\n",
    "for cls in classes:\n",
    "    cls_dir = os.path.join(train_dir, cls)\n",
    "    for img in os.listdir(cls_dir):\n",
    "        image_paths.append(os.path.join(cls_dir, img))\n",
    "        labels.append(cls)\n",
    "\n",
    "# Convert to a DataFrame\n",
    "data = pd.DataFrame({\"image_path\": image_paths, \"label\": labels})\n",
    "\n",
    "# Monte Carlo Cross-Validation configuration\n",
    "n_splits = 5  # Number of iterations (splits)\n",
    "train_ratio = 0.8  # Ratio of data to be used for training\n",
    "\n",
    "# Loop through each Monte Carlo split\n",
    "for split in range(1, n_splits + 1):\n",
    "    print(f\"Processing Split {split}...\")\n",
    "    split_dir = os.path.join(output_dir, f\"Split_{split}\")\n",
    "    split_train_dir = os.path.join(split_dir, \"Train\")\n",
    "    split_val_dir = os.path.join(split_dir, \"Validation\")\n",
    "    split_test_dir = os.path.join(split_dir, \"Test\")\n",
    "\n",
    "    # Create directories for Train, Validation, and Test\n",
    "    for folder in [split_train_dir, split_val_dir, split_test_dir]:\n",
    "        for cls in classes:\n",
    "            os.makedirs(os.path.join(folder, cls), exist_ok=True)\n",
    "\n",
    "    # Split data into training and validation sets for the current split\n",
    "    train_data, val_data = train_test_split(\n",
    "        data, test_size=1 - train_ratio, stratify=data[\"label\"], random_state=split * 42\n",
    "    )\n",
    "\n",
    "    # Copy training images\n",
    "    for _, row in train_data.iterrows():\n",
    "        src = row[\"image_path\"]\n",
    "        label = row[\"label\"]\n",
    "        dst = os.path.join(split_train_dir, label, os.path.basename(src))\n",
    "        shutil.copy(src, dst)\n",
    "\n",
    "    # Copy validation images\n",
    "    for _, row in val_data.iterrows():\n",
    "        src = row[\"image_path\"]\n",
    "        label = row[\"label\"]\n",
    "        dst = os.path.join(split_val_dir, label, os.path.basename(src))\n",
    "        shutil.copy(src, dst)\n",
    "\n",
    "    # Copy fixed testing dataset\n",
    "    for cls in classes:\n",
    "        cls_test_dir = os.path.join(test_dir, cls)\n",
    "        for img in os.listdir(cls_test_dir):\n",
    "            src = os.path.join(cls_test_dir, img)\n",
    "            dst = os.path.join(split_test_dir, cls, os.path.basename(img))\n",
    "            shutil.copy(src, dst)\n",
    "\n",
    "print(\"Monte Carlo Cross-Validation dataset splits created in E:\\\\Modified Dataset.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e98ee1-2d42-47d1-adba-92b5ebd58d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Dataset details\n",
    "base_dir = r\"D:\\3rd sem Project\\Secondary dataset\\CXR collection\\17000 Dataset\\Dataset\"\n",
    "output_dir = r\"E:\\Modified Dataset\"\n",
    "train_dir = os.path.join(base_dir, \"train\")\n",
    "test_dir = os.path.join(base_dir, \"test\")  # Fixed test dataset directory\n",
    "classes = [\"NORMAL\", \"PNEUMONIA\", \"ABNORMAL\"]\n",
    "\n",
    "# Create a list of all images and their labels (from the training directory)\n",
    "image_paths = []\n",
    "labels = []\n",
    "\n",
    "for cls in classes:\n",
    "    cls_dir = os.path.join(train_dir, cls)\n",
    "    for img in os.listdir(cls_dir):\n",
    "        image_paths.append(os.path.join(cls_dir, img))\n",
    "        labels.append(cls)\n",
    "\n",
    "# Convert to a DataFrame\n",
    "data = pd.DataFrame({\"image_path\": image_paths, \"label\": labels})\n",
    "\n",
    "# Bootstrap Sampling configuration\n",
    "n_iterations = 5  # Number of bootstrap iterations\n",
    "sample_ratio = 0.8  # Ratio of data to be used for sampling\n",
    "\n",
    "# Loop through each bootstrap iteration\n",
    "for iteration in range(1, n_iterations + 1):\n",
    "    print(f\"Processing Bootstrap Iteration {iteration}...\")\n",
    "    iteration_dir = os.path.join(output_dir, f\"Iteration_{iteration}\")\n",
    "    iteration_train_dir = os.path.join(iteration_dir, \"Train\")\n",
    "    iteration_val_dir = os.path.join(iteration_dir, \"Validation\")\n",
    "    iteration_test_dir = os.path.join(iteration_dir, \"Test\")\n",
    "\n",
    "    # Create directories for Train, Validation, and Test\n",
    "    for folder in [iteration_train_dir, iteration_val_dir, iteration_test_dir]:\n",
    "        for cls in classes:\n",
    "            os.makedirs(os.path.join(folder, cls), exist_ok=True)\n",
    "\n",
    "    # Bootstrap sampling for training data\n",
    "    train_data = resample(data, n_samples=int(len(data) * sample_ratio), stratify=data[\"label\"], random_state=iteration * 42)\n",
    "    val_data = data.drop(train_data.index)\n",
    "\n",
    "    # Copy training images\n",
    "    for _, row in train_data.iterrows():\n",
    "        src = row[\"image_path\"]\n",
    "        label = row[\"label\"]\n",
    "        dst = os.path.join(iteration_train_dir, label, os.path.basename(src))\n",
    "        shutil.copy(src, dst)\n",
    "\n",
    "    # Copy validation images\n",
    "    for _, row in val_data.iterrows():\n",
    "        src = row[\"image_path\"]\n",
    "        label = row[\"label\"]\n",
    "        dst = os.path.join(iteration_val_dir, label, os.path.basename(src))\n",
    "        shutil.copy(src, dst)\n",
    "\n",
    "    # Copy fixed testing dataset\n",
    "    for cls in classes:\n",
    "        cls_test_dir = os.path.join(test_dir, cls)\n",
    "        for img in os.listdir(cls_test_dir):\n",
    "            src = os.path.join(cls_test_dir, img)\n",
    "            dst = os.path.join(iteration_test_dir, cls, os.path.basename(img))\n",
    "            shutil.copy(src, dst)\n",
    "\n",
    "print(\"Bootstrap dataset splits created in E:\\\\Modified Dataset.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21793761-a460-4653-881e-eb9cf9102cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Dataset details\n",
    "base_dir = r\"D:\\3rd sem Project\\Secondary dataset\\CXR collection\\17000 Dataset\\Dataset\"\n",
    "output_dir = r\"E:\\Modified Dataset\"\n",
    "train_dir = os.path.join(base_dir, \"train\")\n",
    "test_dir = os.path.join(base_dir, \"test\")  # Fixed test dataset directory\n",
    "classes = [\"NORMAL\", \"PNEUMONIA\", \"ABNORMAL\"]\n",
    "\n",
    "# Create a list of all images and their labels (from the training directory)\n",
    "image_paths = []\n",
    "labels = []\n",
    "\n",
    "for cls in classes:\n",
    "    cls_dir = os.path.join(train_dir, cls)\n",
    "    for img in os.listdir(cls_dir):\n",
    "        image_paths.append(os.path.join(cls_dir, img))\n",
    "        labels.append(cls)\n",
    "\n",
    "# Convert to a DataFrame\n",
    "data = pd.DataFrame({\"image_path\": image_paths, \"label\": labels})\n",
    "\n",
    "# K-Fold Cross-Validation configuration\n",
    "n_splits = 5  # Number of folds\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Loop through each fold\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(data)):\n",
    "    print(f\"Processing Fold {fold + 1}...\")\n",
    "    fold_dir = os.path.join(output_dir, f\"Fold_{fold + 1}\")\n",
    "    fold_train_dir = os.path.join(fold_dir, \"Train\")\n",
    "    fold_val_dir = os.path.join(fold_dir, \"Validation\")\n",
    "    fold_test_dir = os.path.join(fold_dir, \"Test\")\n",
    "\n",
    "    # Create directories for Train, Validation, and Test\n",
    "    for folder in [fold_train_dir, fold_val_dir, fold_test_dir]:\n",
    "        for cls in classes:\n",
    "            os.makedirs(os.path.join(folder, cls), exist_ok=True)\n",
    "\n",
    "    # Split data into training and validation sets for the current fold\n",
    "    train_data = data.iloc[train_idx]\n",
    "    val_data = data.iloc[val_idx]\n",
    "\n",
    "    # Copy training images\n",
    "    for _, row in train_data.iterrows():\n",
    "        src = row[\"image_path\"]\n",
    "        label = row[\"label\"]\n",
    "        dst = os.path.join(fold_train_dir, label, os.path.basename(src))\n",
    "        shutil.copy(src, dst)\n",
    "\n",
    "    # Copy validation images\n",
    "    for _, row in val_data.iterrows():\n",
    "        src = row[\"image_path\"]\n",
    "        label = row[\"label\"]\n",
    "        dst = os.path.join(fold_val_dir, label, os.path.basename(src))\n",
    "        shutil.copy(src, dst)\n",
    "\n",
    "    # Copy fixed testing dataset\n",
    "    for cls in classes:\n",
    "        cls_test_dir = os.path.join(test_dir, cls)\n",
    "        for img in os.listdir(cls_test_dir):\n",
    "            src = os.path.join(cls_test_dir, img)\n",
    "            dst = os.path.join(fold_test_dir, cls, os.path.basename(img))\n",
    "            shutil.copy(src, dst)\n",
    "\n",
    "print(\"K-Fold Cross-Validation dataset splits created in E:\\\\Modified Dataset.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
